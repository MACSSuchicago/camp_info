---
title: Multivariate distributions
---

```{r common-r, code = xfun::read_utf8(here::here("_common.R")), include = FALSE}
```

# Properties of a joint PDF

Continuous random variables $X$ and $Y$ have the following joint probability density function (PDF):^[Grimmer HW12.1]

$$
\begin{aligned}
f_{XY} (x, y) &= \begin{cases}
k x^2 y^3 & \text{where} \; 0 < x, y < 6 \\
0 & \text{otherwise}
\end{cases}
\end{aligned}
$$

> Note: $0 < x,y <6$ means that both $x$ and $y$ are between 0 and 6; it does not mean that $x$ is greater than 0 and $y$ is less than 6. This notation is not uncommon, so keep it in mind.

a. Find $k$.

    <!--

    **Solution**:
    
    $$
    \begin{aligned}
    \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f_{XY} (x, y) \, dx \, dy &= 1 \\
    \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} kx^2y^3 \, dx \, dy &= 1 \\
    \int_{0}^{6} \int_{0}^{6}  kx^2y^3 \, dx \, dy &= 1 \\
    k \int_{0}^{6} \int_{0}^{6}  x^2 y^3 \, dx \, dy &= 1 \\
    k \int_{0}^{6} y^3 \cdot \frac{x^3}{3} \Big|_0^6 \, dy &= 1 \\
    k \int_{0}^{6} y^3 \cdot \left(\frac{6^3}{3} - 0 \right) \, dy &= 1 \\
    72 k \int_{0}^{6} y^3 \, dy &= 1 \\
    72 k \cdot \frac{y^4}{4} \Big|_0^6 &= 1 \\
    72 k \left(\frac{6^4}{4} - 0 \right)  &= 1 \\
    72k \cdot 324 &= 1\\
    23328 k &= 1 \\
    k &= \frac{1}{23328}
    \end{aligned}
    $$

    -->

a. Find the marginal PDF of $X$, $f_X (x)$.

    <!--

    **Solution:**

    $$
    \begin{aligned}
    f_X (x) &= \int_{-\infty}^{\infty} f_{XY} (x, y) \, dy \\
    &=  \int_{-\infty}^{\infty} \frac{x^2 y^3}{23328} \, dy\\
    &= \int_{0}^{6} \frac{x^2 y^3}{23328} \, dy \\
    &= \frac{x^2}{23328} \int_{0}^{6} y^3 \, dy \\
    &= \frac{x^2}{23328} \cdot \frac{y^4}{4} \Big|_0^6 \\
    &= \frac{x^2}{23328} \cdot \frac{6^4}{4} \\
    &= \frac{x^2}{72}
    \end{aligned}
    $$

    -->
    
a. Find the marginal PDF of $Y$, $f_Y (y)$.

    <!--

    **Solution:**
    
    $$
    \begin{aligned}
    f_{Y}(y) &= \int_{-\infty}^\infty f(x,y) \, dx\\
    &= \frac{1}{23328} \int_0^6 x^2 y^3 \, dx\\
    &= \frac{1}{23328} \cdot \frac{x^3}{3}\bigg|_0^6 y^3\\
    &= \frac{1}{23328} \left(\frac{216}{3} - 0\right) y^3\\
    &= \frac{1}{23328}\ (72)\ y^3\\
    &= \frac{y^3}{324}
    \end{aligned}
    $$
    
    -->

a. Find E$[X]$.

    <!--

    **Solution:**
    
    $$
    \begin{aligned}
    \E[X] &= \int_{-\infty}^\infty \int_{-\infty}^\infty x f(x,y) \, dx \, dy\\
    &= \frac{1}{23328} \int_0^6 \int_0^6 x \cdot x^2 y^3 \, dx \, dy\\
    &= \frac{1}{23328} \times \int_0^6 x^3 \, dx \times \int_0^6 y^3 \, dy\\
    &= \frac{1}{23328} \times \frac{x^4}{4}\bigg|_0^6 \times \frac{y^4}{4}\bigg|_0^6\\
    &= \frac{1}{23328} \left(\frac{1296}{4} - 0\right) \left(\frac{1296}{4} - 0\right)\\
    &= \frac{1}{23328}\ (324)\ (324)\\
    &= 4.5
    \end{aligned}
    $$
    
    -->

a. Find E$[Y]$.

    <!--

    **Solution:**
    
    $$
    \begin{aligned}
    \E[Y] &= \int_{-\infty}^\infty \int_{-\infty}^\infty y f(x,y) \, dx \, dy\\
    &= \frac{1}{23328} \int_0^6 \int_0^6 y \cdot x^2 y^3 \, dx \, dy\\
    &= \frac{1}{23328} \times \int_0^6 x^2 \, dx \times \int_0^6 y^4 \, dy\\
    &= \frac{1}{23328} \times \frac{x^3}{3}\bigg|_0^6 \times \frac{y^5}{5}\bigg|_0^6\\
    &= \frac{1}{23328} \left(\frac{216}{3} - 0\right) \left(\frac{6^5}{5} - 0\right)\\
    &= \frac{1}{23328}\ (72) \left(\frac{7776}{5}\right)\\
    &= 4.8
    \end{aligned}
    $$
    
    -->

a. Find $\Var(X)$.

    <!--

    **Solution:** To find $\Var(X)$, we first need to find $\E[X^2]$.
    
    $$
    \begin{aligned}
    \E[X^2] &= \frac{1}{23328} \int_0^6 \int_0^6 x^2 \cdot x^2 y^3 \, dx \, dy\\
    &= \frac{1}{23328} \times \int_0^6 \int_0^6 x^4 y^3 \, dx \, dy\\
    &= \frac{1}{23328} \times \int_0^6 x^4 \, dx \times \int_0^6 y^3 \, dy\\
    &= \frac{1}{23328} \times \frac{x^5}{5}\bigg|_0^6 \times \frac{y^4}{4}\bigg|_0^6\\
    &= \frac{1}{23328} \left(\frac{7776}{5} - 0\right) \left(\frac{1296}{4} - 0\right)\\
    &= \frac{1}{23328} \left(\frac{7776}{5}\right) (324)\\
    &= 21.6
    \end{aligned} 
    $$
    
    With $\E[X^2]$ determined, we can now calculate $\Var(X)$.
    
    $$
    \begin{aligned}
    \Var(X) &= \E[X^2] - \E[X]^2\\
    &= 21.6 - (4.5)^2\\
    &= 21.6 - 20.25\\
    &= 1.35
    \end{aligned}
    $$
    
    -->

a. Find $\Var(Y)$.

    <!--

    **Solution:** Again, to find $\Var(Y)$, we first need $\E[Y^2]$.
    
    $$
    \begin{aligned}
    \E[Y^2] &= \frac{1}{23328} \int_0^6 \int_0^6 y^2 \cdot x^2 y^3 \, dx \, dy\\
    &= \frac{1}{23328} \times \int_0^6 \int_0^6 x^2 y^5 \, dx \, dy\\
    &= \frac{1}{23328} \times \int_0^6 x^2 \, dx \times \int_0^6 y^5 \, dy\\
    &= \frac{1}{23328} \times \frac{x^3}{3}\bigg|_0^6 \times \frac{y^6}{6}\bigg|_0^6\\
    &= \frac{1}{23328} \left(\frac{216}{3} - 0\right) \left(7776 - 0\right)\\
    &= \frac{1}{23328} (72) (7776)\\
    &= 24
    \end{aligned} 
    $$
    
    With $\E[Y^2]$ in hand, we can now calculate $\Var(Y)$.
    
    $$
    \begin{aligned}
    \Var(Y) &= \E[Y^2] - \E[Y]^2\\
    &= 24 - (4.8)^2\\
    &= 24 - 23.04\\
    &= 0.96
    \end{aligned}
    $$
    
    -->

a. Find $\Cov(X, Y)$.

    <!--

    **Solution:** To find $\Cov(X,Y)$, we first need $\E[XY]$.
    
    $$
    \begin{aligned}
    \E[XY] &= \frac{1}{23328} \int_0^6 \int_0^6 xy \cdot x^2 y^3 \, dx \, dy\\
    &= \frac{1}{23328} \times \int_0^6 \int_0^6 x^3 y^4 \, dx \, dy\\
    &= \frac{1}{23328} \times \int_0^6 x^3 \, dx \times \int_0^6 y^4 \, dy\\
    &= \frac{1}{23328} \times \frac{x^4}{4}\bigg|_0^6 \times \frac{y^5}{5}\bigg|_0^6\\
    &= \frac{1}{23328} \left(\frac{1296}{4} - 0\right) \left(\frac{7776}{5} - 0\right)\\
    &= \frac{1}{23328} (324) \left(\frac{7776}{5}\right)\\
    &= 21.6
    \end{aligned}
    $$
    
    Now, we calculate $\Cov(X,Y)$.
    
    $$
    \begin{aligned}
    \Cov(X,Y) &= \E[XY] - \E[X]\E[Y]\\
    &= 21.6 - (4.5)(4.8)\\
    &= 21.6 - 21.6\\
    &= 0
    \end{aligned}
    $$
    
    -->

a. Are $X$ and $Y$ independent? Why?

    <!--

    **Solution:** $X$ and $Y$ are independent because $f_{XY} (x, y) = f_X(x) f_Y(y)$ (definition of independence), or in other words, the product of the marginal densities of $X$ and $Y$ is equal to the joint density of $X$ and $Y$:
    
    $$f_X(x) f_Y(y) = \frac{x^2}{72} \left( \frac{y^3}{324} \right) = \frac{x^2 y^3}{23328} = f_{XY} (x, y)$$
    
    We **cannot** say that $X$ and $Y$ are independent because the covariance is zero. While it is true that independent variables have a covariance of zero, it is not necessarily true that variables with a covariance of zero are independent.
    
    -->

a. What is the PDF of $X$ conditional on $Y, f_{X|Y} (x|y)$?

    <!--

    **Solution:** We've previously shown that X and Y are independent. This implies that $f(x) = f(x|y)$ so the answer is the same as the marginal distribution of x from part (b), 
    
    $$
    \begin{aligned}
    f(x|y) &= f(x)\\
    &= \dfrac{x^2}{72}
    \end{aligned}
    $$
    
    -->

a. What is the PDF of $Y$ conditional on $X, f_{Y|X} (y|x)$? 

    <!--

    **Solution:** Again since we've already shown that X and Y are independent we can just refer back to the answer to (c).
    
    $$
    \begin{aligned}
    f (y|x) &= f(y)\\
    &= \dfrac{y^3}{324}
    \end{aligned}
    $$
    
    -->

# Properties of joint random variables^[Grimmer HW12.3]

* $\E[D] = 10$
* $\E[F] = 4$
* $\E[DF] = 8$
* $\Var(D) = 60$
* $\Var(F) = 60$

a. What is $\Cov(D,F)$?

    <!--

    $$
    \begin{aligned}
    \Cov(D,F) &= \E[DF] - \E[D]\E[F]\\
    &= 8 - (4\times10)\\
    &= -32
    \end{aligned}
    $$
    
    -->

a. What is the correlation between $D$ and $F$?

    <!--

    $$
    \begin{aligned}
    \Cor(D,F) &= \dfrac{\Cov(D,F)}{\sqrt{\Var(F)\Var(D)}}\\
    &= \dfrac{-32}{\sqrt{60\times60}}\\
    &= -0.5333333
    \end{aligned}
    $$
    
    -->

a. Suppose you multiplied $F$ by 2 to generate a new variable, $H$. What is $\Cov(D,H)$?

    <!--

    **Solution:** Multiplying F by 2 increases the magnitude of the covariance between $D$ and $H$. 
    
    $$
    \begin{aligned}
    \Cov(D,H) &= \E[DH] - \E[D]\E[H]\\
    \E[DH] &= \E[D \times 2F] = \int 2 DF f(D,F) d(D,F) = 2 \int DF f(D,F) d(D,F) = 2\E[DF] = 16\\
    \E[H] &= \E[2F] = \int 2 F f(F) dF = 2 \int F f(F) dF = 2\E[F] = 8\\
    \Cov(D,H) &= 16 - (8\times10) = -64\\
    \end{aligned}
    $$	
    
    -->
	
a. What is $\Cor(D,H)$? How does this compare to your answer to Part (b) of this question?

    <!--

    $$
    \begin{aligned}
    \Var(H) &= \Var(2F) =  2^2 \Var(F) = 4\times60 = 240\\
    \Cor( D,H) &= \dfrac{\Cov(D,H)}{\sqrt{\Var(F) \Var(H)}}\\
    &= \dfrac{-64}{\sqrt{60 \times 240}}\\
    &= -0.5333333
    \end{aligned}
    $$
    
    This is the same as $\Cor(D,F)$. In other words, multiplying one of the variables by a constant leaves the correlation between the two variables unchanged. This occurs despite the covariance changing. 
    
    -->

a. Suppose instead that $\Var(D) = 30$. How would this change $\Cor(D,F)$?

    <!--

    **Solution:** The magnitude of the correlation between the variables increases as Var(D) decreases:
    
    $$
    \begin{aligned}
    \Cor(D,F) &= \dfrac{\Cov(D,F)}{\sqrt{\Var(F)\Var(D)}}\\
    &= \dfrac{-32}{\sqrt{60*30}}\\
    &= -0.7542472
    \end{aligned}
    $$
    
    -->

# Calculating conditional PDF

Let $f(x,y) = 15x^2y$ for $0 \leq x \leq y \leq 1$. Find $f(x|y)$.^[Grimmer HW12.4]

<!--

**Solution:**

$$
\begin{aligned}
f(y) &= \int_0^y f(x,y) \, dx\\
&= \int_0^y  15x^2y \, dx\\
&= 15y \int_0^y  x^2 \, dx\\
&= 15y \dfrac{x^3}{3} \bigg|_0^y\\
&= \dfrac{15y^4}{3}\\
f(x|y) &= \dfrac{f(x,y)}{f(y)}\\
&= \dfrac{15x^2y}{15y^4/3}\\
&= \dfrac{3x^2}{y^3} \\
\end{aligned}
$$

-->

# Deriving a joint PDF

We start with a stick of length $l$. We break it at a point which is chosen according to a uniform distribution and keep the piece, of length $Y$, that contains the left end of the stick. We then repeat the same process on the piece that we were left with, and let $X$ be the length of the remaining piece after breaking for the second time.^[BT 3.21]

a. Find the joint PDF of $Y$ and $X$

    <!--

    **Solution:** We have
    
    $$f_Y(y) = \frac{1}{l}, \forall \, 0 \leq y \leq l$$
    
    Furthermore, given the value $y$ of $Y$, the random variable $X$ is uniform in the interval $[0, y]$. Therefore
    
    $$f_{X | Y} (x | y) = \frac{1}{y}, \forall \, 0 \leq x \leq y$$
    
    We conclude that
    
    $$f_{X,Y}(x,y) = f_Y(y) f_{X|Y} (x | y) = \begin{cases}
    \frac{1}{l} \times \frac{1}{y} &, 0 \leq x \leq y \leq l, \\
    0 &, \text{otherwise}
    \end{cases}$$
    
    -->

a. Find the marginal PDF of $X$

    <!--

    **Solution:** We have
    
    $$f_X(x) = \int f_{X,Y} (x,y) \, dy = \int\limits_x^l \frac{1}{ly} \, dy = \frac{1}{l} \log \left(\frac{l}{x} \right), \forall \, 0 \leq x \leq l$$
    
    -->
    
a. Use the PDF of $X$ to evaluate $\E[X]$

    <!--

    **Solution:** We have
    
    $$\E[X] = \int\limits_0^l x f_X(x) \, dx = \int\limits_0^l \frac{x}{l} \log \left(\frac{l}{x} \right) \, dx = \frac{l}{4}$$
    
    -->

a. Evaluate $\E[X]$, by exploiting the relation $X = Y \times \dfrac{X}{Y}$

    <!--

    **Solution:** The fraction $\dfrac{Y}{l}$ of the stick that is left after the first break, and the further fraction $\dfrac{X}{Y}$ of the stick that is left after the second break are independent. Furthermore, the random variables $Y$ and $\dfrac{X}{Y}$ are uniformly distributed over the sets $[0,l]$ and $[0,1]$, respectively, so that $\E[Y] = \dfrac{l}{2}$ and $\E\left[\dfrac{X}{Y}\right] = \dfrac{1}{2}$. Thus,
    
    $$\E[X] = \E[Y] \E \left[ \frac{X}{Y} \right] = \frac{l}{2} \times \frac{1}{2} = \frac{l}{4}$$
    
    -->

# Continuous Bayes' theorem

Previously, we used Bayes' theorem to link the conditional probability of discrete events $A$ given $B$ to the probability of $B$ given $A$. There is an analogous Bayes' theorem that relates the conditional densities of random variables $X$ and $\theta$:

$$f(\theta \mid X) = \frac{f(X \mid \theta) f(\theta)}{\int f(X \mid \theta) f(\theta)d\theta}$$

Prove the continuous Bayes' theorem.^[Grimmer HW12.5]

<!--

**Solution:**

Recall the definition of the conditional distribution of two random variables:

$$f_{\theta \mid X}(\theta \mid X) = \frac{f(\theta, X)}{f_X(X)}$$

Remember via the "chain rule" of probability that $f(\theta, X) = f(X \mid \theta)f_\theta(\theta)$, and via our rule for marginalization, $f_X(X) = \int f_{X\mid \theta}(X \mid \theta)f_\theta(\theta)d\theta$. Substitute these equalities in and we have proven the statement:

$$
\begin{aligned}
f_{\theta \mid X}(\theta \mid X) &= \frac{f(\theta, X)}{f_X(X)} \\
&= \frac{ f(X \mid \theta)f_\theta(\theta)}{\int f_{X\mid \theta}(X \mid \theta)f(\theta)d\theta}
\end{aligned}
$$

-->
